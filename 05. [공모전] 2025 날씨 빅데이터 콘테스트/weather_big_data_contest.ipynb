{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c250bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import optuna\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import json\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 train 데이터\n",
    "df = pd.read_csv('train_call.csv', encoding = 'cp949')\n",
    "\n",
    "# 결측치 명시\n",
    "df = df.replace(-99.0, None)\n",
    "\n",
    "# 컬럼명 정리\n",
    "df.columns = df.columns.str.replace('^call119_train\\\\.', '', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db1599",
   "metadata": {},
   "source": [
    "# 데이터 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968d4b7",
   "metadata": {},
   "source": [
    "### 구별 이전 달의 주민등록인구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'address_gu' 별 주민등록인구: KOSIS > 지역통계 > 인구 및 사회 (사회조사 외) > 부산광역시 > 부산광역시주민등록인구통계 > 주민등록인구총괄 > 부산광역시 전체 세대 및 인구개황\n",
    "gu_pop = pd.read_csv('gu_pop.csv', encoding = 'cp949', dtype = {'시점': str}, na_values = '-')\n",
    "\n",
    "# 컬럼명 정리\n",
    "gu_pop = gu_pop.rename(\n",
    "    columns = {'시점': 'tm',\n",
    "               '구·군별': 'address_gu',\n",
    "               '읍면동수 (개)': 'sub_address_count',\n",
    "               '세대수 (세대)': 'gu_household',\n",
    "               '인구수  (명)': 'gu_pop',\n",
    "               '남자인구수 (명)': 'gu_male_pop',\n",
    "               '여자인구수 (명)': 'gu_female_pop',\n",
    "               '시전체 인구에 대한 구성비 (%)': 'gu_pop_ratio',\n",
    "               '면적 (㎢)': 'gu_area',\n",
    "               '인구밀도 (명/㎢)': 'gu_density'}\n",
    ")\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "gu_pop['tm'] = pd.to_datetime(gu_pop['tm'].astype(str), format = '%Y.%m')\n",
    "gu_pop['year'] = gu_pop['tm'].dt.year.astype(int)\n",
    "gu_pop['month'] = gu_pop['tm'].dt.month.astype(int)\n",
    "gu_pop = gu_pop.drop('tm', axis = 1)\n",
    "\n",
    "# 불필요한 날짜 제거\n",
    "gu_pop = gu_pop[gu_pop['month'].isin(range(4, 10))].reset_index(drop = True)\n",
    "\n",
    "# 이전 달의 정보를 현재의 feature로 이동\n",
    "gu_pop['month'] = gu_pop['month'] + 1\n",
    "\n",
    "# 회의 후 drop\n",
    "gu_pop = gu_pop.drop(\n",
    "    ['sub_address_count', 'gu_household', 'gu_pop', 'gu_male_pop', 'gu_female_pop'],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# 저장\n",
    "gu_pop.to_csv('merge0.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "gu_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e5402",
   "metadata": {},
   "source": [
    "### 읍면동별 이전 달의 주민등록인구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 'sub_address' 별 주민등록인구: KOSIS > 지역통계 > 인구 및 사회 (사회조사 외) > 부산광역시 > 부산광역시주민등록인구통계 > 주민등록인구총괄 > 구·군 및 읍·면·동 세대와 인구\n",
    "# --------------------------------------------------\n",
    "# 행정동 변경으로 인해, 일부 지역은 평균치로 대체함\n",
    "# --------------------------------------------------\n",
    "sub_pop = pd.read_csv('sub_pop.csv', encoding = 'cp949', dtype = {'시점': str}, na_values = '-')\n",
    "\n",
    "# 불필요한 컬럼 삭제\n",
    "sub_pop = sub_pop.drop(['내외국인별', 'Unnamed: 7'], axis = 1)\n",
    "\n",
    "\n",
    "# 컬럼명 정리\n",
    "sub_pop = sub_pop.rename(\n",
    "    columns = {'구·군별': 'sub_address',\n",
    "               '시점': 'tm',\n",
    "               '세대수[세대]': 'sub_household',\n",
    "               '인구[명]': 'sub_pop',\n",
    "               '남자인구[명]': 'sub_male_pop',\n",
    "               '여자인구[명]': 'sub_female_pop'}\n",
    ")\n",
    "\n",
    "# 'address_gu' 컬럼 추가 (송정동은 강서구와 해운대구에 모두 존재)\n",
    "gu_set = set(df['address_gu'])\n",
    "sub_pop['address_gu'] = sub_pop['sub_address'].where(\n",
    "    sub_pop['sub_address'].isin(gu_set)\n",
    ")\n",
    "sub_pop['address_gu'] = sub_pop['address_gu'].ffill()\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "sub_pop['tm'] = sub_pop['tm'].str.replace(\n",
    "    r'\\s[가-힣]+', '', regex = True\n",
    ")\n",
    "sub_pop['tm'] = pd.to_datetime(sub_pop['tm'].astype(str), format = '%Y.%m')\n",
    "sub_pop['year'] = sub_pop['tm'].dt.year.astype(int)\n",
    "sub_pop['month'] = sub_pop['tm'].dt.month.astype(int)\n",
    "sub_pop = sub_pop.drop('tm', axis = 1)\n",
    "\n",
    "# 불필요한 날짜 제거\n",
    "sub_pop = sub_pop[sub_pop['month'].isin(range(4, 10))].reset_index(drop = True)\n",
    "\n",
    "# 이전 달의 정보를 현재의 feature로 이동\n",
    "sub_pop['month'] = sub_pop['month'] + 1\n",
    "\n",
    "# 'sub_address'가 'address_gu'인 자료 제거\n",
    "sub_pop = sub_pop[~sub_pop['sub_address'].isin(gu_set)]\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 'sub_address' 별 1인 가구 수: KOSIS > 지역통계 > 인구 및 사회 (사회조사 외) > 부산광역시 > 부산광역시주민등록인구통계 > 주민등록인구총괄 > 읍·면·동별 세대원수별 세대수\n",
    "# --------------------------------------------------\n",
    "# 행정동 변경으로 인한 결측치를 함께 대체하기 위해 통합\n",
    "# --------------------------------------------------\n",
    "sub_single = pd.read_csv('sub_single.csv', encoding = 'cp949', dtype = {'시점': str}, na_values = '-')\n",
    "\n",
    "# 컬럼명 정리\n",
    "sub_single = sub_single.rename(\n",
    "    columns = {'시점': 'tm',\n",
    "               '구·군별(1)': 'address_gu',\n",
    "               '구·군별(2)': 'sub_address',\n",
    "               '1인': 'sub_single'}\n",
    ")\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "sub_single['tm'] = pd.to_datetime(sub_single['tm'].astype(str), format = '%Y.%m')\n",
    "sub_single['year'] = sub_single['tm'].dt.year.astype(int)\n",
    "sub_single['month'] = sub_single['tm'].dt.month.astype(int)\n",
    "sub_single = sub_single.drop('tm', axis = 1)\n",
    "\n",
    "# 불필요한 날짜 제거\n",
    "sub_single = sub_single[sub_single['month'].isin(range(4, 10))].reset_index(drop = True)\n",
    "\n",
    "# 이전 달의 정보를 현재의 feature로 이동\n",
    "sub_single['month'] = sub_single['month'] + 1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 통합\n",
    "# --------------------------------------------------\n",
    "sub_pop = sub_pop.merge(sub_single, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화가 없는 'sub_address'\n",
    "# --------------------------------------------------\n",
    "# ! ! !단, '일광면'과 '정관면'은 train 및 test 데이터를 수정 ! ! !\n",
    "# --------------------------------------------------\n",
    "A0 = sub_pop[\n",
    "    ~sub_pop['sub_address']\n",
    "    .isin([\n",
    "        '중앙동', '영주1동', '영주2동', '광복동',\n",
    "        '부민동', '충무동', '남항동', '부전1동',\n",
    "        '부전2동', '수민동', '복산동', '반송1동',\n",
    "        '반송2동', '금사회동동', '청룡노포동', '선두구동',\n",
    "        '부곡1동', '부곡2동', '부곡3동', '부곡4동',\n",
    "        '녹산동', '송정동', '가덕도동', '가락동',\n",
    "        '대저1동', '대저2동'\n",
    "    ])\n",
    "]\n",
    "A0 = A0.copy()\n",
    "A0['sub_address'] = A0['sub_address'].str.replace(\n",
    "    '[0-9]+(?=동)', '', regex = True\n",
    ")\n",
    "A0 = A0.groupby(['year', 'month', 'address_gu', 'sub_address']).sum().reset_index()\n",
    "A1 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['대저1동', '대저2동'])\n",
    "]\n",
    "A = pd.concat([A0, A1], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: 대창동 <- (중앙동, 영주동) / 중앙동 <- 중앙동 / (대창동, 영주동) <- 영주동\n",
    "# --------------------------------------------------\n",
    "B0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['중앙동', '영주1동', '영주2동'])\n",
    "]\n",
    "\n",
    "B0 = B0.copy()\n",
    "B0['sub_address'] = B0['sub_address'].str.replace(\n",
    "    '[0-9]+(?=동)', '', regex = True\n",
    ")\n",
    "B0 = B0.groupby(['year', 'month', 'address_gu', 'sub_address']).sum().reset_index()\n",
    "\n",
    "# 대창동\n",
    "B1 = B0.copy()\n",
    "B1 = B1.groupby(['year', 'month', 'address_gu'])[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]].mean().reset_index()\n",
    "B1['sub_address'] = '대창동'\n",
    "\n",
    "# 중앙동\n",
    "B2 = B0.copy()\n",
    "B2 = B2.loc[B2['sub_address'] == '중앙동', :] \n",
    "B2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = B2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "\n",
    "# 영주동\n",
    "B3 = B0.copy()\n",
    "B3 = B3.loc[B3['sub_address'] == '영주동', :] \n",
    "B3[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = B3[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "\n",
    "# 통합\n",
    "B = pd.concat([B1, B2, B3], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (신창동, 광복동, 창선동) <- 광복동\n",
    "# --------------------------------------------------\n",
    "C0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['광복동'])\n",
    "]\n",
    "\n",
    "# 광복동\n",
    "C1 = C0.copy() \n",
    "C1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = C1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 3\n",
    "\n",
    "# 신창동\n",
    "C2 = C1.copy() \n",
    "C2['sub_address'] = '신창동'\n",
    "\n",
    "# 창선동\n",
    "C3 = C1.copy() \n",
    "C3['sub_address'] = '창선동'\n",
    "\n",
    "# 통합\n",
    "C = pd.concat([C1, C2, C3], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (부민동, 부용동) <- 부민동\n",
    "# --------------------------------------------------\n",
    "D0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['부민동'])\n",
    "]\n",
    "\n",
    "# 부민동\n",
    "D1 = D0.copy()\n",
    "D1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = D1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "\n",
    "# 부용동\n",
    "D2 = D1.copy()\n",
    "D2['sub_address'] = '부용동'\n",
    "\n",
    "# 통합\n",
    "D = pd.concat([D1, D2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (충무동, 토성동) <- 충무동\n",
    "# --------------------------------------------------\n",
    "E0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['충무동'])\n",
    "]\n",
    "\n",
    "# 충무동\n",
    "E1 = E0.copy()\n",
    "E1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = E1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "\n",
    "# 토성동\n",
    "E2 = E1.copy()\n",
    "E2['sub_address'] = '토성동'\n",
    "\n",
    "# 통합\n",
    "E = pd.concat([E1, E2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (남항동, 대교동, 대평동) <- 남항동\n",
    "# --------------------------------------------------\n",
    "F0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['남항동'])\n",
    "]\n",
    "\n",
    "# 남항동\n",
    "F1 = F0.copy()\n",
    "F1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = F1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 3\n",
    "\n",
    "# 대교동\n",
    "F2 = F1.copy()\n",
    "F2['sub_address'] = '대교동'\n",
    "\n",
    "# 대평동\n",
    "F3 = F1.copy()\n",
    "F3['sub_address'] = '대평동'\n",
    "\n",
    "# 통합\n",
    "F = pd.concat([F1, F2, F3], ignore_index = True)\n",
    "\n",
    "# 저장\n",
    "#sub_pop.to_csv('merge1.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (부전동, 범전동) <- 부전1동, 부전동 <- 부전2동\n",
    "# --------------------------------------------------\n",
    "G0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['부전1동', '부전2동'])\n",
    "]\n",
    "\n",
    "# 부전동\n",
    "G1 = G0.copy()\n",
    "G1 = G1.groupby(['year', 'month', 'address_gu'])[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]].mean().reset_index()\n",
    "G1['sub_address'] = '부전동'\n",
    "\n",
    "# 범전동\n",
    "G2 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['부전1동'])\n",
    "]\n",
    "G2 = G2.copy()\n",
    "G2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = G2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "G2['sub_address'] = '범전동'\n",
    "\n",
    "# 통합\n",
    "G = pd.concat([G1, G2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (낙민동, 수안동) <- 수민동\n",
    "# --------------------------------------------------\n",
    "H0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['수민동'])\n",
    "]\n",
    "\n",
    "# 낙민동\n",
    "H1 = H0.copy()\n",
    "H1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = H1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "H1['sub_address'] = '낙민동'\n",
    "\n",
    "# 수안동\n",
    "H2 = H1.copy()\n",
    "H2['sub_address'] = '수안동'\n",
    "\n",
    "# 통합\n",
    "H = pd.concat([H1, H2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (복천동, 칠산동) <- 복산동\n",
    "# --------------------------------------------------\n",
    "I0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['복산동'])\n",
    "]\n",
    "\n",
    "# 복천동\n",
    "I1 = I0.copy()\n",
    "I1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = I1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "I1['sub_address'] = '복천동'\n",
    "\n",
    "# 칠산동\n",
    "I2 = I1.copy()\n",
    "I2['sub_address'] = '칠산동'\n",
    "\n",
    "# 통합\n",
    "I = pd.concat([I1, I2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (반송동, 석대동) <- 반송1동, 반송동 <- 반송2동\n",
    "# --------------------------------------------------\n",
    "J0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['반송1동', '반송2동'])\n",
    "]\n",
    "\n",
    "# 반송동\n",
    "J1 = J0.copy()\n",
    "J1 = J1.groupby(['year', 'month', 'address_gu'])[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]].mean().reset_index()\n",
    "J1['sub_address'] = '반송동'\n",
    "\n",
    "# 석대동\n",
    "J2 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['반송1동'])\n",
    "]\n",
    "J2 = J2.copy()\n",
    "J2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = J2[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "J2['sub_address'] = '석대동'\n",
    "\n",
    "# 통합\n",
    "J = pd.concat([J1, J2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (금사동, 회동동) <- 금사회동동\n",
    "# --------------------------------------------------\n",
    "K0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['금사회동동'])\n",
    "]\n",
    "\n",
    "# 금사동\n",
    "K1 = K0.copy()\n",
    "K1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = K1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "K1['sub_address'] = '금사동'\n",
    "\n",
    "# 회동동\n",
    "K2 = K1.copy()\n",
    "K2['sub_address'] = '회동동'\n",
    "\n",
    "# 통합\n",
    "K = pd.concat([K1, K2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (청룡동, 노포동) <- 청룡노포동\n",
    "# --------------------------------------------------\n",
    "L0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['청룡노포동'])\n",
    "]\n",
    "\n",
    "# 청룡동\n",
    "L1 = L0.copy()\n",
    "L1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = L1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "L1['sub_address'] = '청룡동'\n",
    "\n",
    "# 노포동\n",
    "L2 = L1.copy()\n",
    "L2['sub_address'] = '노포동'\n",
    "\n",
    "# 통합\n",
    "L = pd.concat([L1, L2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (선동, 두구동) <- 선두구동\n",
    "# --------------------------------------------------\n",
    "M0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['선두구동'])\n",
    "]\n",
    "\n",
    "# 선동\n",
    "M1 = M0.copy()\n",
    "M1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = M1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "M1['sub_address'] = '선동'\n",
    "\n",
    "# 두구동\n",
    "M2 = M1.copy()\n",
    "M2['sub_address'] = '두구동'\n",
    "\n",
    "# 통합\n",
    "M = pd.concat([M1, M2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: 오륜동 <- 부곡3동, 부곡동 <- (부곡1동, 부곡2동, 부곡3동, 부곡4동)\n",
    "# --------------------------------------------------\n",
    "# 오륜동\n",
    "N1 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['부곡3동'])\n",
    "]\n",
    "N1 = N1.copy()\n",
    "N1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = N1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 2\n",
    "N1['sub_address'] = '오륜동'\n",
    "\n",
    "# 부곡동\n",
    "N2 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['부곡1동', '부곡2동', '부곡4동'])\n",
    "]\n",
    "N2 = N2.copy()\n",
    "N2 = pd.concat([N1, N2])\n",
    "N2 = N2.groupby(['year', 'month', 'address_gu'])[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]].sum().reset_index()\n",
    "N2['sub_address'] = '부곡동'\n",
    "\n",
    "# 통합\n",
    "N = pd.concat([N1, N2], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (녹산동, 구랑동, 미음동, 범방동, 생곡동, 화전동, 지사동, 신호동, 송정동) <- 녹산동, 송정동 <- 송정동\n",
    "# --------------------------------------------------\n",
    "# ! ! ! 강서구의 송정동 (해운대에도 송정동이 있음) ! ! !\n",
    "# --------------------------------------------------\n",
    "# 녹산동\n",
    "O1 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['녹산동'])\n",
    "]\n",
    "O1 = O1.copy()\n",
    "O1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = O1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 9\n",
    "\n",
    "# 구랑동, 미음동, 범방동, 생곡동, 화전동, 지사동, 신호동\n",
    "O2 = O1.copy()\n",
    "O2['sub_address'] = '구랑동'\n",
    "O3 = O1.copy()\n",
    "O3['sub_address'] = '미음동'\n",
    "O4 = O1.copy()\n",
    "O4['sub_address'] = '범방동'\n",
    "O5 = O1.copy()\n",
    "O5['sub_address'] = '생곡동'\n",
    "O6 = O1.copy()\n",
    "O6['sub_address'] = '화전동'\n",
    "O7 = O1.copy()\n",
    "O7['sub_address'] = '지사동'\n",
    "O8 = O1.copy()\n",
    "O8['sub_address'] = '신호동'\n",
    "\n",
    "# 강서구 송정동\n",
    "O9 = O1.copy()\n",
    "O9['sub_address'] = '송정동'\n",
    "\n",
    "# 통합\n",
    "O = pd.concat([O1, O2, O3, O4, O5, O6, O7, O8, O9], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 해운대구 송정동\n",
    "# --------------------------------------------------\n",
    "P = sub_pop[\n",
    "    (sub_pop['sub_address']\n",
    "    .isin(['송정동'])) &\n",
    "    (sub_pop['address_gu'] == '해운대구')\n",
    "]\n",
    "P = P.reset_index(drop = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (눌차동, 대항동, 동선동, 성북동, 천성동) <- 가덕도동\n",
    "# --------------------------------------------------\n",
    "Q0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['가덕도동'])\n",
    "]\n",
    "\n",
    "# 눌차동\n",
    "Q1 = Q0.copy()\n",
    "Q1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = Q1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 5\n",
    "Q1['sub_address'] = '눌차동'\n",
    "\n",
    "# 대항동, 동선동, 성북동, 천성동\n",
    "Q2 = Q1.copy()\n",
    "Q2['sub_address'] = '대항동'\n",
    "Q3 = Q1.copy()\n",
    "Q3['sub_address'] = '동선동'\n",
    "Q4 = Q1.copy()\n",
    "Q4['sub_address'] = '성북동'\n",
    "Q5 = Q1.copy()\n",
    "Q5['sub_address'] = '천성동'\n",
    "\n",
    "# 통합\n",
    "Q = pd.concat([Q1, Q2, Q3, Q4, Q5], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 행정동 변화: (봉림동, 식만동, 죽동동, 죽림동) <- 가락동\n",
    "# --------------------------------------------------\n",
    "R0 = sub_pop[\n",
    "    sub_pop['sub_address']\n",
    "    .isin(['가락동'])\n",
    "]\n",
    "\n",
    "# 봉림동\n",
    "R1 = R0.copy()\n",
    "R1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] = R1[[\n",
    "    'sub_household', 'sub_pop', 'sub_male_pop', 'sub_female_pop', 'sub_single'\n",
    "]] / 4\n",
    "R1['sub_address'] = '봉림동'\n",
    "\n",
    "# 식만동, 죽동동, 죽림동\n",
    "R2 = R1.copy()\n",
    "R2['sub_address'] = '식만동'\n",
    "R3 = R1.copy()\n",
    "R3['sub_address'] = '죽동동'\n",
    "R4 = R1.copy()\n",
    "R4['sub_address'] = '죽림동'\n",
    "\n",
    "# 통합\n",
    "R = pd.concat([R1, R2, R3, R4], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 통합\n",
    "# --------------------------------------------------\n",
    "sub_pop_imputed = pd.concat([A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R], ignore_index = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 저장\n",
    "# --------------------------------------------------\n",
    "sub_pop_imputed.to_csv('merge1.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 조회\n",
    "# --------------------------------------------------\n",
    "sub_pop_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160a478",
   "metadata": {},
   "source": [
    "### 구별 이전 달의 고령인구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273aa2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'address_gu' 별 65세 이상 고령인구: KOSIS > 지역통계 > 인구 및 사회 (사회조사 외) > 부산광역시 > 부산광역시주민등록인구통계 > 구·군별 연령별 현황 > 구·군별 연령별(5세) 인구\n",
    "gu_old = pd.read_csv('gu_old.csv', encoding = 'cp949', dtype = {'시점': str}, na_values = '-')\n",
    "\n",
    "# 불필요한 컬럼 삭제\n",
    "gu_old = gu_old.drop('연령별(1)', axis = 1)\n",
    "\n",
    "# 컬럼명 정리\n",
    "gu_old = gu_old.rename(\n",
    "    columns = {'시점': 'tm',\n",
    "               '구군별(1)': 'address_gu',\n",
    "               '계': 'gu_old',\n",
    "               '남자': 'gu_male_old',\n",
    "               '여자': 'gu_female_old'}\n",
    ")\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "gu_old['tm'] = pd.to_datetime(gu_old['tm'].astype(str), format = '%Y.%m')\n",
    "gu_old['year'] = gu_old['tm'].dt.year.astype(int)\n",
    "gu_old['month'] = gu_old['tm'].dt.month.astype(int)\n",
    "gu_old = gu_old.drop('tm', axis = 1)\n",
    "\n",
    "# 불필요한 날짜 제거\n",
    "gu_old = gu_old[gu_old['month'].isin(range(4, 10))].reset_index(drop = True)\n",
    "\n",
    "# 이전 달의 정보를 현재의 feature로 이동\n",
    "gu_old['month'] = gu_old['month'] + 1\n",
    "\n",
    "# 저장\n",
    "gu_old.to_csv('merge2.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "gu_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092088f5",
   "metadata": {},
   "source": [
    "### 신고가 일어난 가장 최근 날까지의 신고 카테고리별 누적 건수 및 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed767f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 신고가 일어난 가장 최근 날까지의 신고 카테고리별 누적 건수 및 비율: 'train_cat.csv', 'test_cat119.csv'\n",
    "# --------------------------------------------------\n",
    "# ! ! ! 2020년은 NaN이 너무 많아져서 그냥 해당 년도의 자료를 사용 ! ! !\n",
    "# --------------------------------------------------\n",
    "# ! ! ! 'call_count'가 없는 2024년은 모두 2020-2023년의 median으로 대체 ! ! ! \n",
    "# --------------------------------------------------\n",
    "cat1 = pd.read_csv('train_cat.csv', encoding = 'cp949')\n",
    "cat2 = pd.read_csv('test_cat119.csv', encoding = 'cp949')\n",
    "\n",
    "# 컬럼명 정리\n",
    "cat1.columns = cat1.columns.str.replace('^cat119_train\\\\.', '', regex = True)\n",
    "cat2 = cat2.rename(\n",
    "    columns = {'TM': 'tm', 'STN': 'stn'}\n",
    ")\n",
    "\n",
    "# 불필요한 컬럼 정리\n",
    "cat1 = cat1.drop(['Unnamed: 0', 'address_city', 'stn'], axis = 1)\n",
    "cat2 = cat2.drop(['address_city', 'stn'], axis = 1)\n",
    "\n",
    "# 2024년 'sub_cat' 별 'call_count' imputation\n",
    "# ! ! ! 2020-2023년에는 기타>상황출동만 존재하지만, 2024년에는 구조>상황출동이 하나 존재함. 'cat' 무시하고 기타>상황출동의 값으로 imputation ! ! !\n",
    "impute2024 = cat1.groupby(['sub_cat'])['call_count'].median().reset_index()\n",
    "cat2 = cat2.merge(impute2024, how = 'left', on = ['sub_cat'])\n",
    "\n",
    "# 2020-2024 통합\n",
    "cat = pd.concat([cat1, cat2], ignore_index = True)\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "cat['tm'] = pd.to_datetime(cat['tm'].astype(str), format = '%Y%m%d')\n",
    "cat['tm'] = cat['tm'] + pd.Timedelta(days = 1) # (1) 대희 딸깎\n",
    "cat['year'] = cat['tm'].dt.year.astype(int)\n",
    "cat['month'] = cat['tm'].dt.month.astype(int)\n",
    "cat['day'] = cat['tm'].dt.day.astype(int)\n",
    "cat = cat.drop('tm', axis = 1)\n",
    "\n",
    "# 행정구 통일\n",
    "cat['sub_address'] = cat['sub_address'].replace({'일광면': '일광읍', '정관면': '정관읍'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 'cat' 비율 및 건수 계산\n",
    "# --------------------------------------------------\n",
    "# 'cat'별 'call_count' 합계\n",
    "pivot_cat = cat.copy().groupby([\n",
    "    'year', 'month', 'day', 'address_gu', 'sub_address', 'cat'\n",
    "])['call_count'].sum().reset_index()\n",
    "\n",
    "# 'cat'을 컬럼으로 pivot\n",
    "pivot_cat = pivot_cat.pivot_table(\n",
    "    index = ['year', 'month', 'day', 'address_gu', 'sub_address'],\n",
    "    columns = 'cat',\n",
    "    values = 'call_count',\n",
    "    fill_value = 0\n",
    ").reset_index()\n",
    "\n",
    "# 'call_sum' (날짜 + 지역 별 총 'call _count') 계산\n",
    "cat_cols = pivot_cat.columns.difference(\n",
    "    ['year', 'month', 'day', 'address_gu', 'sub_address']\n",
    ").to_list()\n",
    "pivot_cat['call_sum'] = pivot_cat[cat_cols].sum(axis = 1)\n",
    "\n",
    "# 날짜 범위 만들기\n",
    "date_range = pd.date_range(start = '2020-05-01', end = '2024-10-31', freq='D')\n",
    "date_df = pd.DataFrame({\n",
    "    'year': date_range.year,\n",
    "    'month': date_range.month,\n",
    "    'day': date_range.day\n",
    "})\n",
    "\n",
    "# Unique 'address_gu' + 'sub_address' 조합 추출\n",
    "sub_addrs = pivot_cat[['address_gu', 'sub_address']].drop_duplicates()\n",
    "sub_addrs = sub_addrs.sort_values(['address_gu', 'sub_address']).reset_index(drop = True)\n",
    "\n",
    "# 'year' + 'month' + 'day' + 'address_gu' + 'sub_address' 조합 생성\n",
    "full_index = date_df.merge(sub_addrs, how = 'cross')\n",
    "\n",
    "# 생성된 모든 조합과 'pivot_cat'을 병합\n",
    "pivot_cat_filled = full_index.merge(\n",
    "    pivot_cat, \n",
    "    on = ['year', 'month', 'day', 'address_gu', 'sub_address'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "# 빈 날짜 + 지역의 신고 건수 결측치를 0으로 설정\n",
    "pivot_cat_filled.fillna(0, inplace = True)\n",
    "\n",
    "# 정렬\n",
    "pivot_cat_filled = pivot_cat_filled.sort_values([\n",
    "    'address_gu', 'sub_address', 'year', 'month', 'day'\n",
    "]).reset_index(drop = True)\n",
    "\n",
    "# 'call_sum' (누적 'call _count') 누적합 계산\n",
    "pivot_cat_filled['cum_call_sum'] = pivot_cat_filled.groupby([\n",
    "    'address_gu', 'sub_address' # (2) 대희야 여기 'address_gu'가 빠져서 송정동 ratio 합이 1이 안되서 추가했다\n",
    "])['call_sum'].cumsum()\n",
    "\n",
    "# 'cat' 별 'call_sum' 계산\n",
    "for col in cat_cols:\n",
    "    cum_col = f'cum_{col}'\n",
    "    pivot_cat_filled[cum_col] = pivot_cat_filled.groupby([\n",
    "        'address_gu', 'sub_address'\n",
    "    ])[col].cumsum()\n",
    "\n",
    "# 누적 비율 계산\n",
    "for col in cat_cols:\n",
    "    pivot_cat_filled[f'cum_{col}_ratio'] = pivot_cat_filled[f'cum_{col}'] / pivot_cat_filled['cum_call_sum']\n",
    "\n",
    "# 비율 결측치를 0으로 설정\n",
    "pivot_cat_filled.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69767f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 'sub_cat' 비율 및 건수 계산\n",
    "# --------------------------------------------------\n",
    "# 'sub_cat'별 'call_count' 합계\n",
    "pivot_subcat = cat.copy().groupby([\n",
    "    'year', 'month', 'day', 'address_gu', 'sub_address', 'sub_cat'\n",
    "])['call_count'].sum().reset_index()\n",
    "\n",
    "# 'sub_cat'을 컬럼으로 pivot\n",
    "pivot_subcat = pivot_subcat.pivot_table(\n",
    "    index=['year', 'month', 'day', 'address_gu', 'sub_address'],\n",
    "    columns='sub_cat',\n",
    "    values='call_count',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# 'call_sum' (날짜 + 지역 별 총 'call _count') 계산\n",
    "subcat_cols = pivot_subcat.columns.difference(\n",
    "    ['year', 'month', 'day', 'address_gu', 'sub_address']\n",
    ").to_list()\n",
    "pivot_subcat['call_sum'] = pivot_subcat[subcat_cols].sum(axis = 1)\n",
    "\n",
    "# 'year' + 'month' + 'day' + 'address_gu' + 'sub_address' 조합과 'pivot_subcat'을 병합\n",
    "pivot_subcat_filled = full_index.merge(\n",
    "    pivot_subcat, \n",
    "    on = ['year', 'month', 'day', 'address_gu', 'sub_address'],\n",
    "    how = 'left'\n",
    ")\n",
    "\n",
    "# 빈 날짜 + 지역의 신고 건수 결측치를 0으로 설정\n",
    "pivot_subcat_filled.fillna(0, inplace = True)\n",
    "\n",
    "# 정렬\n",
    "pivot_subcat_filled = pivot_subcat_filled.sort_values([\n",
    "    'address_gu', 'sub_address', 'year', 'month', 'day'\n",
    "]).reset_index(drop = True)\n",
    "\n",
    "# 'call_sum' (누적 'call _count') 누적합 계산\n",
    "pivot_subcat_filled['cum_call_sum'] = pivot_subcat_filled.groupby([\n",
    "    'address_gu', 'sub_address'\n",
    "])['call_sum'].cumsum()\n",
    "\n",
    "# 'sub_cat'별 'call_sum' 계산\n",
    "for col in subcat_cols:\n",
    "    cum_col = f'cum_{col}'\n",
    "    pivot_subcat_filled[cum_col] = pivot_subcat_filled.groupby([\n",
    "        'address_gu', 'sub_address'\n",
    "    ])[col].cumsum()\n",
    "\n",
    "# 누적 비율 계산\n",
    "for col in subcat_cols:\n",
    "    pivot_subcat_filled[f'cum_{col}_ratio'] = pivot_subcat_filled[f'cum_{col}'] / pivot_subcat_filled['cum_call_sum']\n",
    "\n",
    "# 비율 결측치를 0으로 설정\n",
    "pivot_subcat_filled.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f81179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 병합\n",
    "# --------------------------------------------------\n",
    "# 혹시 모르니 동일한 순서로 정렬\n",
    "sort_keys = ['year', 'month', 'day', 'address_gu', 'sub_address']\n",
    "pivot_cat_filled = pivot_cat_filled.sort_values(by = sort_keys).reset_index(drop = True)\n",
    "pivot_subcat_filled = pivot_subcat_filled.sort_values(by = sort_keys).reset_index(drop = True)\n",
    "\n",
    "# 키 컬럼 중복 방지를 위해 'pivot_subcat_filled'에서 키 컬럼, 중복 컬럼 제외\n",
    "pivot_subcat_filled_only = pivot_subcat_filled.drop(\n",
    "    columns = ['year', 'month', 'day', 'address_gu', 'sub_address', 'call_sum', 'cum_call_sum'] # (3) 대희 같은 컬럼이 더 있었습니다\n",
    ")\n",
    "\n",
    "# 중복된 컬럼명 변경\n",
    "pivot_subcat_filled_only = pivot_subcat_filled_only.rename(\n",
    "    columns = {'cum_기타': 'cum_sub_기타',\n",
    "               'cum_기타_ratio': 'cum_sub_기타_ratio',\n",
    "               '기타': 'cum_sub_기타_ratio'}\n",
    ") # (4) 대희 합치니까 이상한 suffix가 생기길래 확인해 보니 이름이 같은 컬럼들이 있었습니다\n",
    "\n",
    "# 병합\n",
    "pivot_df = pd.concat([pivot_cat_filled, pivot_subcat_filled_only], axis = 1)\n",
    "\n",
    "# 불필요한 날짜 삭제\n",
    "pivot_df = pivot_df[pivot_df['month'].isin(range(5, 11))].reset_index(drop = True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 휘의 후 필요한 컬럼만 선택: 구급 기타만 'sub_cat'에서 가져감\n",
    "# --------------------------------------------------\n",
    "pivot_df = pivot_df.loc[:, pivot_cat_filled.columns.to_list() + ['구급기타', 'cum_구급기타', 'cum_구급기타_ratio']]\n",
    "pivot_df = pivot_df.copy()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 저장\n",
    "# --------------------------------------------------\n",
    "pivot_df.to_csv('merge4.csv', index = False, encoding = 'cp949') \n",
    "\n",
    "# --------------------------------------------------\n",
    "# 조회\n",
    "# --------------------------------------------------\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef26c9a",
   "metadata": {},
   "source": [
    "### 구별 위경도와 지역 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'address_gu'의 위경도: 국토부 브이월드 > 공간정보 다운로드 > 행정구역시군구_경계 > 위경도 추출\n",
    "gu_lat_lon = pd.read_csv(\"gu_lat_lon.csv\", encoding = 'cp949')\n",
    "\n",
    "# address_gu 만들고 남은거 drop\n",
    "gu_lat_lon['address_gu'] = gu_lat_lon['SGG_NM'].str.replace('부산광역시 ', '', regex = False)\n",
    "gu_lat_lon = gu_lat_lon.drop(columns = ['ADM_SECT_C', 'SGG_NM', 'SGG_OID', 'COL_ADM_SE'])\n",
    "\n",
    "# 클러스터 추가(Elbow, Silhouette 참고 => 4개 설정)\n",
    "gu_lat_lon['gu_cluster'] = KMeans(n_clusters = 4, random_state = 42).fit_predict(\n",
    "    gu_lat_lon[['gu_lat', 'gu_lon']]\n",
    ")\n",
    "gu_lat_lon['gu_cluster'] = gu_lat_lon['gu_cluster'].astype(object)\n",
    "\n",
    "# 저장\n",
    "gu_lat_lon.to_csv('merge6.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "gu_lat_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869d018",
   "metadata": {},
   "source": [
    "### 읍면동별 위경도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국토부 브이월드 > 공간정보 다운로드 > 행정구역_읍면동(법정동) > QGIS 정제 > 'sub_address'의 위도 및 경도 추출\n",
    "sub_lat_lon = pd.read_csv(\"sub_lat_lon.csv\", encoding = 'cp949')\n",
    "\n",
    "# address_gu, sub_address로 groupby해서 위경도 평균 구하기\n",
    "sub_lat_lon = sub_lat_lon.groupby([\n",
    "    'address_gu', 'sub_address'\n",
    "])[[\n",
    "    'latitude', 'longitude'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# 컬럼명 변경(sub_lat, sub_lon)\n",
    "sub_lat_lon = sub_lat_lon.rename(columns = {\n",
    "    'latitude': 'sub_lat',\n",
    "    'longitude': 'sub_lon'\n",
    "})\n",
    "\n",
    "# 저장\n",
    "sub_lat_lon.to_csv('merge7.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "sub_lat_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792e29c",
   "metadata": {},
   "source": [
    "### 읍면동 별 전년도의 신고 건수 중간값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fd3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "py = df.copy()[['tm', 'address_gu', 'sub_address', 'call_count']]\n",
    "py['sub_address'] = py['sub_address'].replace({'일광면': '일광읍', '정관면': '정관읍'})\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "py['tm'] = pd.to_datetime(py['tm'].astype(str), format = '%Y%m%d')\n",
    "py['year'] = py['tm'].dt.year.astype(int)\n",
    "py['month'] = py['tm'].dt.month.astype(int)\n",
    "\n",
    "# 날짜 범위\n",
    "date_range = pd.date_range(start = '2020-05-01', end = '2024-10-31', freq='ME')\n",
    "date_df = pd.DataFrame({\n",
    "    'year': date_range.year,\n",
    "    'month': date_range.month\n",
    "})\n",
    "\n",
    "# Unique 'address_gu' + 'sub_address' 조합 추출\n",
    "sub_addrs = py[['address_gu', 'sub_address']].drop_duplicates()\n",
    "sub_addrs = sub_addrs.sort_values(['address_gu', 'sub_address']).reset_index(drop = True)\n",
    "\n",
    "# 'year' + 'month' + 'day' + 'address_gu' + 'sub_address' 조합 생성\n",
    "full_index = date_df.merge(sub_addrs, how = 'cross')\n",
    "full_index = full_index.loc[full_index['month'].isin(range(5, 11))]\n",
    "\n",
    "# 금년 중간값\n",
    "prev_year_call_med = py.groupby(\n",
    "    ['year', 'month', 'address_gu', 'sub_address']\n",
    ")['call_count'].median().reset_index()\n",
    "\n",
    "# 작년 중앙값\n",
    "prev_year_call_med['year'] += 1\n",
    "\n",
    "# 병합\n",
    "prev_year_call_med = full_index.merge(\n",
    "    prev_year_call_med,\n",
    "    how = 'left',\n",
    "    on = ['year', 'month', 'address_gu', 'sub_address']\n",
    ")\n",
    "\n",
    "# 결측값은 연도에 무관한 월별 중간값으로 대체\n",
    "prev_year_call_med['call_count'] = prev_year_call_med['call_count'].fillna(\n",
    "    prev_year_call_med.groupby(['month', 'address_gu', 'sub_address'])['call_count'].transform('median')\n",
    ")\n",
    "\n",
    "# 대체하고도 사건이 일어나지 않아 결측치인 값은 0으로 대체\n",
    "prev_year_call_med.fillna(0, inplace = True)\n",
    "\n",
    "# 컬럼명 정리\n",
    "prev_year_call_med = prev_year_call_med.rename(\n",
    "    columns = {'call_count': 'prev_year_call_med'}\n",
    ")\n",
    "\n",
    "# 저장\n",
    "prev_year_call_med.to_csv('merge8.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "prev_year_call_med"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf594db",
   "metadata": {},
   "source": [
    "### 읍면동 별 전년도 월별 신고 카테고리 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb22925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# 전년도 월별 신고 카테고리별 누적 건수 및 비율: 'train_cat.csv'\n",
    "# --------------------------------------------------\n",
    "# ! ! ! 2020년은 NaN이 너무 많아져서 그냥 해당 년도의 자료를 사용 ! ! !\n",
    "# --------------------------------------------------\n",
    "# 바로 전 'year'의 'sub_address' 별 'cat' 비율\n",
    "call_ratio = pd.read_csv('train_cat.csv', encoding = 'cp949')\n",
    "\n",
    "# 컬럼명 정리\n",
    "call_ratio.columns = call_ratio.columns.str.replace('^cat119_train\\\\.', '', regex = True)\n",
    "\n",
    "# 날짜 컬럼 정리\n",
    "call_ratio['tm'] = pd.to_datetime(call_ratio['tm'].astype(str), format = '%Y%m%d')\n",
    "call_ratio['year'] = call_ratio['tm'].dt.year.astype(int)\n",
    "call_ratio['month'] = call_ratio['tm'].dt.month.astype(int)\n",
    "\n",
    "# 행정구 통일\n",
    "call_ratio['sub_address'] = call_ratio['sub_address'].replace({'일광면': '일광읍', '정관면': '정관읍'})\n",
    "\n",
    "# 'cat' 비율\n",
    "r1 = call_ratio.copy().groupby(['year', 'month', 'address_gu', 'sub_address', 'cat'])['call_count'].sum().reset_index()\n",
    "r1_tot = call_ratio.copy().groupby(['year', 'month', 'address_gu','sub_address'])['call_count'].sum().reset_index()\n",
    "r1['year'] = r1['year'] + 1\n",
    "r1_tot['year'] = r1_tot['year'] + 1\n",
    "\n",
    "r1 = r1.merge(r1_tot, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "r1['ratio'] = r1['call_count_x'] / r1['call_count_y']\n",
    "\n",
    "r1 = r1.pivot(index = ['year', 'month', 'address_gu', 'sub_address'], columns = 'cat', values = 'ratio').reset_index()\n",
    "r1 = r1.fillna(0)\n",
    "r1.columns = ['year', 'month', 'address_gu', 'sub_address'] + [f'prev_year_{col}' for col in r1.columns[4: ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바로 전 'year'의 'sub_address' 별 'sub_cat' 비율\n",
    "r2 = call_ratio.copy().groupby(['year', 'month', 'address_gu', 'sub_address', 'sub_cat'])['call_count'].sum().reset_index()\n",
    "r2_tot = call_ratio.copy().groupby(['year', 'month', 'address_gu','sub_address'])['call_count'].sum().reset_index()\n",
    "r2['year'] = r2['year'] + 1\n",
    "r2_tot['year'] = r2_tot['year'] + 1\n",
    "\n",
    "r2 = r2.merge(r2_tot, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "r2['ratio'] = r2['call_count_x'] / r2['call_count_y']\n",
    "\n",
    "r2 = r2.pivot(index = ['year', 'month', 'address_gu', 'sub_address'], columns = 'sub_cat', values = 'ratio').reset_index()\n",
    "r2 = r2.fillna(0)\n",
    "r2.columns = ['year', 'month', 'address_gu', 'sub_address'] + [f'prev_year_{col}' for col in r2.columns[4: ]]\n",
    "\n",
    "r2 = r2.rename(columns = {'prev_year_기타': 'prev_year_sub_기타'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합\n",
    "r = pd.merge(r1, r2, 'inner', ['year', 'month', 'address_gu', 'sub_address'])\n",
    "\n",
    "# 날짜 범위\n",
    "date_range = pd.date_range(start = '2020-05-01', end = '2024-10-31', freq = 'ME')\n",
    "date_df = pd.DataFrame({\n",
    "    'year': date_range.year,\n",
    "    'month': date_range.month\n",
    "})\n",
    "\n",
    "# Unique 'address_gu' + 'sub_address' 조합 추출\n",
    "sub_addrs = r[['address_gu', 'sub_address']].drop_duplicates()\n",
    "sub_addrs = sub_addrs.sort_values(['address_gu', 'sub_address']).reset_index(drop = True)\n",
    "\n",
    "# 'year' + 'month' + 'day' + 'address_gu' + 'sub_address' 조합 생성\n",
    "full_index = date_df.merge(sub_addrs, how = 'cross')\n",
    "full_index = full_index.loc[full_index['month'].isin(range(5, 11))]\n",
    "\n",
    "# 빈 날짜 + 지역 조합 채우기\n",
    "r = full_index.merge(\n",
    "    r,\n",
    "    how = 'left',\n",
    "    on = ['year', 'month', 'address_gu', 'sub_address']\n",
    ")\n",
    "\n",
    "# 결측값은 연도에 무관한 월별 중간값으로 대체\n",
    "cols_to_fill = r.columns.difference(\n",
    "    ['year', 'month', 'address_gu', 'sub_address']\n",
    ").to_list()\n",
    "\n",
    "r[cols_to_fill] = r[cols_to_fill].fillna(\n",
    "    r.groupby(['month', 'address_gu', 'sub_address'])[cols_to_fill].transform('median')\n",
    ")\n",
    "\n",
    "# 그럼에도 불구하고 결측치가 있다면 0.0으로 대체\n",
    "r.fillna(0, inplace = True)\n",
    "\n",
    "# 회의 후 필요한 컬럼만 선택: 'sub_cat'에서는 '구급기타'만 선택\n",
    "r = r.copy()[['year', 'month', 'address_gu', 'sub_address', 'prev_year_구급',\n",
    "              'prev_year_구조', 'prev_year_기타', 'prev_year_화재', 'prev_year_교통사고',\n",
    "              'prev_year_구급기타']]\n",
    "\n",
    "# 저장\n",
    "r.to_csv('merge9.csv', index = False, encoding = 'cp949')\n",
    "\n",
    "# 조회\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7e1d2",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Test data를 고려해 input에 자동으로 feature를 추가하는 함수 정의\n",
    "# --------------------------------------------------\n",
    "# ! ! ! 입력되는 dataframe은 train 데이터와 같은 dtype과 (prefix를 뗀) 컬럼명을 가져야 함 ! ! !\n",
    "# --------------------------------------------------\n",
    "def wowthatisamazing(x):\n",
    "    out = x.copy()\n",
    "    \n",
    "    # -----\n",
    "    # 날짜를 timestamp로 변환 후 정수 컬럼 'year', 'month', 'day', 'day_of_the_week' 생성\n",
    "    # -----\n",
    "    out['tm'] = pd.to_datetime(out['tm'].astype(str), format = '%Y%m%d')\n",
    "\n",
    "    # 요일\n",
    "    out['day_of_the_week'] = out['tm'].dt.day_name().astype(object)\n",
    "    out['year'] = out['tm'].dt.year.astype(int)\n",
    "    out['month'] = out['tm'].dt.month.astype(int)\n",
    "    out['day'] = out['tm'].dt.day.astype(int)\n",
    "\n",
    "    # -----\n",
    "    # 원본 날짜 컬럼 제거\n",
    "    # -----\n",
    "    out = out.drop('tm', axis = 1)\n",
    "\n",
    "    # -----\n",
    "    # 기상 자료 dtype 정리\n",
    "    # -----\n",
    "    out[[\n",
    "        'ta_max', 'ta_min', 'ta_max_min', 'hm_min', \n",
    "        'hm_max', 'ws_max', 'ws_ins_max', 'rn_day'\n",
    "    ]] = out[[\n",
    "        'ta_max', 'ta_min', 'ta_max_min', 'hm_min', \n",
    "        'hm_max', 'ws_max', 'ws_ins_max', 'rn_day'\n",
    "    ]].astype(float)\n",
    "    out['stn'] = out['stn'].astype(object)\n",
    "\n",
    "    # -----\n",
    "    # 면에서 읍으로 승격된 행정 구역 통일 ('merge2.csv'와 'merge9.csv'가 작동하기 위한 조건)\n",
    "    # -----\n",
    "    out['sub_address'] = out['sub_address'].replace({'일광면': '일광읍', '정관면': '정관읍'})\n",
    "\n",
    "    merge0 = pd.read_csv('merge0.csv', encoding = 'cp949')\n",
    "    merge1 = pd.read_csv('merge1.csv', encoding = 'cp949')\n",
    "    merge2 = pd.read_csv('merge2.csv', encoding = 'cp949')\n",
    "    \n",
    "    merge4 = pd.read_csv('merge4.csv', encoding = 'cp949')\n",
    "    \n",
    "    merge6 = pd.read_csv('merge6.csv', encoding = 'cp949', dtype = {'gu_cluster': object})\n",
    "    merge7 = pd.read_csv('merge7.csv', encoding = 'cp949')\n",
    "    merge8 = pd.read_csv('merge8.csv', encoding = 'cp949')\n",
    "    merge9 = pd.read_csv('merge9.csv', encoding = 'cp949')\n",
    "\n",
    "    out = out.merge(merge0, how = 'left', on = ['year', 'month', 'address_gu'])\n",
    "    out = out.merge(merge1, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "    out = out.merge(merge2, how = 'left', on = ['year', 'month', 'address_gu'])\n",
    "    \n",
    "    out = out.merge(merge4, how = 'left', on = ['year', 'month', 'day', 'address_gu', 'sub_address'])\n",
    "    \n",
    "    out = out.merge(merge6, how = 'left', on = ['address_gu'])\n",
    "    out = out.merge(merge7, how = 'left', on = ['address_gu', 'sub_address'])\n",
    "    out = out.merge(merge8, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "    out = out.merge(merge9, how = 'left', on = ['year', 'month', 'address_gu', 'sub_address'])\n",
    "\n",
    "    # -----\n",
    "    # 날씨 파생 변수\n",
    "    # -----\n",
    "    cols_to_fill = [\n",
    "        'ta_max', 'ta_min', 'ta_max_min', 'hm_min',\n",
    "        'hm_max', 'ws_max', 'ws_ins_max', 'rn_day'\n",
    "    ]\n",
    "\n",
    "    out2 = out.copy()[[\n",
    "        'year', 'month', 'day', 'address_gu', 'sub_address', 'gu_cluster'\n",
    "    ] + cols_to_fill]\n",
    "\n",
    "    # 3단계 rolling 기반 imputation\n",
    "\n",
    "    # 1차: 같은 날짜 + 같은 구의 과거 10일 평균으로 imputation\n",
    "    for col in cols_to_fill:\n",
    "        out2[col] = out2.groupby(['year', 'month', 'day', 'address_gu'])[col].transform(\n",
    "            lambda s: s.fillna(s.shift(1).rolling(window = 10, min_periods = 1).mean())\n",
    "        )\n",
    "\n",
    "    # 2차: 같은 날짜 + 같은 클러스터의 과거 10일 평균으로 imputation\n",
    "    for col in cols_to_fill:\n",
    "        out2[col] = out2.groupby(['year', 'month', 'day', 'gu_cluster'])[col].transform(\n",
    "            lambda s: s.fillna(s.shift(1).rolling(window = 10, min_periods = 1).mean())\n",
    "        )\n",
    "\n",
    "    # 3차: 같은 월 + 같은 클러스터의 과거 10일 평균으로 imputation\n",
    "    for col in cols_to_fill:\n",
    "        out2[col] = out2.groupby(['month', 'gu_cluster'])[col].transform(\n",
    "            lambda s: s.fillna(s.shift(1).rolling(window = 10, min_periods = 1).mean())\n",
    "        )\n",
    "    \n",
    "    # 그럼에도 결측치가 있다면 클러스터의 중간값으로 대체\n",
    "    out2[cols_to_fill] = out2[cols_to_fill].fillna(out2.groupby(['year', 'month', 'day', 'gu_cluster'])[cols_to_fill].transform('median'))\n",
    "\n",
    "    # 생성한 결측치를 원본에 넣음\n",
    "    out[cols_to_fill] = out[cols_to_fill].fillna(out2[cols_to_fill])\n",
    "\n",
    "    # 파생 변수 생성\n",
    "    out['hm_range'] = out['hm_max'] - out['hm_min']\n",
    "    out['ta_hm_ratio'] = out['ta_max'] / out['hm_min']\n",
    "    out['wind_diff'] = out['ws_ins_max'] - out['ws_max']\n",
    "    out['hot_day'] = (out['ta_max'] > 30).astype(int)\n",
    "    out['humid_day'] = (out['hm_min'] > 70).astype(int)\n",
    "    out['windy_day'] = ((out['ws_max'] > 10) | (out['ws_ins_max'] > 15)).astype(int)\n",
    "    out['rainy_day'] = (out['rn_day'] > 0).astype(int)\n",
    "    out['heavy_rain_day'] = (out['rn_day'] >= 30).astype(int)\n",
    "\n",
    "    # 비율 inf를 max로 변경\n",
    "    out['ta_hm_ratio'] = out['ta_hm_ratio'].replace(\n",
    "        np.inf,\n",
    "        out['ta_hm_ratio'][~np.isinf(out['ta_hm_ratio'])].max()\n",
    "    )\n",
    "\n",
    "    # 2020-2023의 날짜 + 구별 날씨 데이터 평균 (모든 날씨는 stn을 기준으로 집계되므로, 관측 지점을 섞어 새로운 변수를 만듬. 'sub_address'별로 집계 시 섞이지 않음)\n",
    "    gu_cols_to_fill = [\n",
    "        'gu_ta_max', 'gu_ta_min', 'gu_ta_max_min', 'gu_hm_min', \n",
    "        'gu_hm_max', 'gu_ws_max', 'gu_ws_ins_max', 'gu_rn_day'\n",
    "    ]\n",
    "    out[gu_cols_to_fill] = out.groupby(\n",
    "        ['year', 'month', 'day', 'address_gu']\n",
    "    )[cols_to_fill].transform('mean')\n",
    "\n",
    "    # -----\n",
    "    # 8월, 9월 여부\n",
    "    # -----\n",
    "    out['is_aug_sep'] = (out['month'].isin([8, 9])).astype(int)\n",
    "\n",
    "    out = out.sort_values(by = ['year', 'month', 'day'], ascending = True, ignore_index = True)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 추가\n",
    "df_full = wowthatisamazing(df)\n",
    "\n",
    "# 출력 변수\n",
    "y = df_full['call_count']\n",
    "\n",
    "# 입력 변수\n",
    "x = df_full.drop(['Unnamed: 0', 'address_city', 'call_count'], axis = 1)\n",
    "\n",
    "# 컬럼 타입 구분\n",
    "num_col = x.select_dtypes(include = 'number').columns.to_list()\n",
    "cat_col = x.select_dtypes(exclude = 'number').columns.to_list()\n",
    "\n",
    "# 전처리기\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', 'passthrough', num_col),\n",
    "    ('cat', TargetEncoder(\n",
    "        target_type = 'continuous', \n",
    "        shuffle = False\n",
    "    ), cat_col)\n",
    "]).set_output(transform = 'pandas')\n",
    "\n",
    "# CV 정의 \n",
    "cv = TimeSeriesSplit(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터\n",
    "test = pd.read_csv('test_call119.csv', encoding = 'cp949')\n",
    "\n",
    "# 컬럼명 정리\n",
    "x_test = test.copy().rename(\n",
    "    columns = {'TM': 'tm',\n",
    "               'STN': 'stn'}\n",
    ")\n",
    "\n",
    "# Feature 추가\n",
    "x_test = wowthatisamazing(x_test)\n",
    "\n",
    "# 불필요한 컬럼 정리\n",
    "x_test = x_test.drop(['address_city', 'call_count'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fdae31",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188a078",
   "metadata": {},
   "source": [
    "### 모형 선택 (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164227e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 파이프라인\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(\n",
    "        objective = 'regression',\n",
    "        subsample_freq = 1, \n",
    "        random_state = 42, \n",
    "        verbosity = -1, \n",
    "        device = 'gpu'\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'model__num_leaves': trial.suggest_int('num_leaves', 31, 256),\n",
    "        'model__max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'model__learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log = True),\n",
    "        'model__n_estimators': trial.suggest_int('n_estimators', 300, 2000),\n",
    "        'model__min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.1),\n",
    "        'model__min_child_samples': trial.suggest_int('min_child_samples', 50, 300),\n",
    "        'model__subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'model__colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'model__reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'model__reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0)\n",
    "    }\n",
    "\n",
    "    optuna_pipeline = clone(pipeline).set_params(**params)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        optuna_pipeline, x, y,\n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        cv = cv,\n",
    "        n_jobs = 4,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    return -scores['test_score'].mean()\n",
    "\n",
    "# Optuna 실행\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "sampler = optuna.samplers.TPESampler(seed = 42)\n",
    "study = optuna.create_study(\n",
    "    direction = 'minimize',\n",
    "    study_name = 'predict_call_count',\n",
    "    sampler = sampler\n",
    ")\n",
    "study.optimize(objective, n_trials = 100, n_jobs = 3, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 결과\n",
    "print('Best parameters:')\n",
    "print(study.best_params)\n",
    "print('Best RMSE:')\n",
    "print(study.best_trial.value)\n",
    "\n",
    "# 최적 파라미터 저장\n",
    "with open('best_params.json', 'w') as f:\n",
    "    json.dump({f'model__{k}': v for k, v in study.best_trial.params.items()}, f, indent = 4)\n",
    "\n",
    "# 최적 RMSE 저장\n",
    "with open('best_rmse.txt', 'w') as f:\n",
    "    f.write(str(study.best_trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b571a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 재학습\n",
    "with open('best_params.json', 'r') as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "best_lgbm = pipeline.set_params(**best_params)\n",
    "best_lgbm = best_lgbm.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a4758",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84194e4f",
   "metadata": {},
   "source": [
    "### 모형 선택 (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 파이프라인\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(\n",
    "        boosting_type = 'rf',\n",
    "        learning_rate = 1.0,\n",
    "        objective = 'regression',\n",
    "        bagging_freq = 1,\n",
    "        min_child_samples = 1,\n",
    "        random_state = 42, \n",
    "        boost_from_average = False,\n",
    "        verbosity = -1, \n",
    "        device = 'gpu'\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca29447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목적 함수\n",
    "def objective2(trial):\n",
    "    params = {\n",
    "        'model__num_leaves': trial.suggest_int('num_leaves', 128, 256),\n",
    "        'model__n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'model__bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 0.9),\n",
    "        'model__feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.9),\n",
    "    }\n",
    "\n",
    "    optuna_pipeline = clone(pipeline2).set_params(**params)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        optuna_pipeline, x, y,\n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        cv = cv,\n",
    "        n_jobs = 4,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    return -scores['test_score'].mean()\n",
    "\n",
    "# Optuna 실행\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "sampler2 = optuna.samplers.TPESampler(seed = 42)\n",
    "study2 = optuna.create_study(\n",
    "    direction = 'minimize',\n",
    "    study_name = 'predict_call_count2',\n",
    "    sampler = sampler2\n",
    ")\n",
    "study2.optimize(objective2, n_trials = 50, n_jobs = 3, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 결과\n",
    "print('Best parameters:')\n",
    "print(study2.best_params)\n",
    "print('Best RMSE:')\n",
    "print(study2.best_trial.value)\n",
    "\n",
    "# 최적 파라미터 저장\n",
    "with open('best_params2.json', 'w') as f:\n",
    "    json.dump({f'model__{k}': v for k, v in study2.best_trial.params.items()}, f, indent = 4)\n",
    "\n",
    "# 최적 RMSE 저장\n",
    "with open('best_rmse2.txt', 'w') as f:\n",
    "    f.write(str(study2.best_trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f016c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 재학습\n",
    "with open('best_params2.json', 'r') as f:\n",
    "    best_params2 = json.load(f)\n",
    "\n",
    "best_rf = pipeline2.set_params(**best_params2)\n",
    "best_rf = best_rf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33dd35",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5be6c",
   "metadata": {},
   "source": [
    "### 모형 선택 (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 파이프라인\n",
    "pipeline3 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(\n",
    "        verbosity = 1,\n",
    "        objective = 'reg:squarederror',\n",
    "        random_state = 42,\n",
    "        tree_method = 'hist',\n",
    "        device = 'cuda'\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목적 함수\n",
    "def objective3(trial):\n",
    "    params = {\n",
    "        'model__n_estimators': trial.suggest_int('n_estimators', 300, 2000),\n",
    "        'model__max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'model__min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'model__gamma': trial.suggest_float('gamma', 0, 10.0),\n",
    "        'model__learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log = True),\n",
    "        'model__subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'model__colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'model__reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'model__reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0)\n",
    "    }\n",
    "\n",
    "    optuna_pipeline = clone(pipeline3).set_params(**params)\n",
    "\n",
    "    scores = cross_validate(\n",
    "        optuna_pipeline, x, y,\n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        cv = cv,\n",
    "        n_jobs = 3,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    return -scores['test_score'].mean()\n",
    "\n",
    "# Optuna 실행\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "sampler3 = optuna.samplers.TPESampler(seed = 42)\n",
    "study3 = optuna.create_study(\n",
    "    direction = 'minimize',\n",
    "    study_name = 'predict_call_count3',\n",
    "    sampler = sampler3\n",
    ")\n",
    "study3.optimize(objective3, n_trials = 100, n_jobs = 3, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 결과\n",
    "print('Best parameters:')\n",
    "print(study3.best_params)\n",
    "print('Best RMSE:')\n",
    "print(study3.best_trial.value)\n",
    "\n",
    "# 최적 파라미터 저장\n",
    "with open('best_params3.json', 'w') as f:\n",
    "    json.dump({f'model__{k}': v for k, v in study3.best_trial.params.items()}, f, indent = 4)\n",
    "\n",
    "# 최적 RMSE 저장\n",
    "with open('best_rmse3.txt', 'w') as f:\n",
    "    f.write(str(study3.best_trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 재학습\n",
    "with open('best_params3.json', 'r') as f:\n",
    "    best_params3 = json.load(f)\n",
    "\n",
    "best_xgb = pipeline3.set_params(**best_params3)\n",
    "best_xgb = best_xgb.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f3bfb",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b121ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 찾아낸 최적 모형들의 예측값으로 ridge regression (메타 모형): CV RMSE를 최소화하는 regularization parameter alpha 탐색\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# RidgeCV\n",
    "alpha_grid = np.logspace(-3, 2, 20)\n",
    "ridge_cv = RidgeCV(alphas = alpha_grid, cv = cv)\n",
    "\n",
    "# StackingRegressor를 위해 XGBoost의 device를 변경 (안 그러면 warning 나옴)\n",
    "best_xgb.set_params(model__device = 'cpu')\n",
    "\n",
    "# Base estimators\n",
    "estimators = [\n",
    "    ('lgbm', best_lgbm),\n",
    "    ('rf', best_rf),\n",
    "    ('xgb', best_xgb)\n",
    "]\n",
    "\n",
    "# Stacking 모델\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators = estimators,\n",
    "    final_estimator = ridge_cv,\n",
    "    cv = 'prefit', # 'prefit': 원래는 매 fold를 학습하고 validate해야 하지만, 너무 오래 걸리므로 leakage를 허용\n",
    "    passthrough = False,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# 학습\n",
    "stacked_model.fit(x, y)\n",
    "\n",
    "# 최적 alpha\n",
    "print(f'Selected alpha: {stacked_model.final_estimator_.alpha_}')\n",
    "print(f'Coefficients:{stacked_model.final_estimator_.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad34f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교를 위한 CV RMSE 계산\n",
    "meta_features = np.column_stack([\n",
    "    best_lgbm.predict(x),\n",
    "    best_rf.predict(x),\n",
    "    best_xgb.predict(x)\n",
    "])\n",
    "scores = cross_validate(ridge_cv, meta_features, y, scoring='neg_root_mean_squared_error', cv = cv)\n",
    "\n",
    "print(\"Ensemble RMSE:\", -scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "submission = stacked_model.predict(x_test)\n",
    "submission = np.clip(np.round(submission), 1, None).astype(int)\n",
    "\n",
    "# 저장\n",
    "test['call_count'] = submission\n",
    "test.to_csv('250259.csv', index = False, encoding = 'cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
